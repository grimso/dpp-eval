{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consolidated Stage\n",
    "\n",
    "The **consolidated stage** combines the results of the **processed stage** for the 4 integrated data sources `awesome-pipeline`,`awesome-data-engineering`,`existing_workflows_systems_revisited`, and `lfai_landscape`. In addition duplicates are removed and missing GitHub repository data is mapped ( manual search  for tools where no respective data was present).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the integrated  data from the **processed stage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awesome_data_engineering\n",
      "(45, 7)\n",
      "awesome_pipelines\n",
      "(165, 5)\n",
      "existing_workflow_systems\n",
      "(263, 6)\n",
      "lfai_landscape\n",
      "(57, 6)\n"
     ]
    }
   ],
   "source": [
    "concat_list=[]\n",
    "for filepath in Path('data/03_processed').glob(\"*.csv\"):\n",
    "    print(filepath.name[:-4])\n",
    "    df = pd.read_csv(filepath)\n",
    "    print(df.shape)\n",
    "    df[\"source\"] = filepath.name[:-4]\n",
    "    concat_list.append(df)\n",
    "\n",
    "df = pd.concat(concat_list).reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove  duplicates \n",
    "\n",
    "Tools can be present in multiple data sources, therefore duplicates need to be removed when combining the data sources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(530, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a helper column to rank the quality of the data sources (subjectively) when dropping duplicates the row with the best score will be kept\n",
    "df[\"source_ranking\"]=df[\"source\"].map({\"awesome_data_engineering\":4,\n",
    "\"awesome_pipelines\":3,\n",
    "\"existing_workflow_systems\":1,\n",
    "\"lfai_landscape\":2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in consistent naming for example apache airflow vs airflow. simply remove apache from ID\n",
    "df[\"id_consolidated\"]=df[\"id\"].str.replace(\"apache\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=[\"id_consolidated\",\"source_ranking\"]).drop_duplicates(subset=\"id\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates using the id_consolidated column (where apache substring is removed) \n",
    "# filter using the source_ranking columns, such that the row with the best source ranking will be kept.\n",
    "df= df.sort_values(by=[\"id_consolidated\",\"source_ranking\"]).drop_duplicates(subset=\"id_consolidated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing data entries for tools\n",
    "\n",
    "For example a code repository (e.g. GitHub URL) was not present in the raw data, although a repository exists.\n",
    "For the combined data at this point a manual research was performed for tools without a repository URL.\n",
    " If the repository url was found for a tool it was added to the mapping below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping with missing information for tools, for example for each tool a repo_url entry way added when found\n",
    "mapping = {\"actionchain\": {\"tool_subcategory\":\"stackstorm\",\"repo_url\":\"https://github.com/StackStorm/st2\"},\n",
    "           \"activepapers\":{\"repo_url\":\"https://github.com/activepapers/activepapers-python\"},\n",
    "           \"arteria\": {\"repo_url\":\"https://github.com/arteria-project/arteria-packs\"},\n",
    "           \"bds\":{\"repo_url\":\"https://github.com/pcingola/bds\",\"homepage_url\":\"https://pcingola.github.io/bds/\"},\n",
    "           \"biokepler\":{\"status\":\"retired\",\"status_comment\":\"url_taken_over\"},\n",
    "           \"bonobo\":{\"repo_url\":\"https://github.com/python-bonobo/bonobo\"},\n",
    "           \"cascading\":{\"repo_url\":\"https://github.com/cwensel/cascading\"},\n",
    "           \"census\":{\"tool_type\":\"commercial\"},\n",
    "           \"clubber\":{\"repo_url\":\"https://bitbucket.org/bromberglab/clubber\"},\n",
    "            \"compss\":{\"repo_url\":\"https://github.com/bsc-wdc/compss\"},\n",
    "            \"datalad\":{\"repo_url\":\"https://github.com/datalad/datalad\"},\n",
    "            \"dbt\":{\"repo_url\":\"https://github.com/dbt-labs/dbt-core\"},\n",
    "            \"doit\":{\"repo_url\":\"https://github.com/pydoit/doit\"},\n",
    "            \"drill\":{\"repo_url\":\"https://github.com/apache/drill\"},\n",
    "            \"apacheflink\":{\"repo_url\":\"https://github.com/apache/flink\"},\n",
    "            \"flowhub\":{\"tool_type\":\"commercial\"},\n",
    "            \"giraph\":{\"repo_url\":\"https://github.com/apache/giraph\"},\n",
    "            \"graphlabcreate\":{\"repo_url\":\"https://github.com/apple/turicreate/\"},\n",
    "            \"guixworkflowlanguage\":{\"alternative_tool_name\":\"gwl\",\"repo_url\":\"https://git.savannah.gnu.org/cgit/gwl.git\"},\n",
    "            \"h2o\":{\"repo_url\":\"https://github.com/h2oai/h2o-3\"},\n",
    "            \"hadoopmapreduce\":{\"repo_url\":\"https://github.com/apache/hadoop\"},\n",
    "            \"apachehudi\":{\"repo_url\":\"https://github.com/apache/hudi\"},\n",
    "            \"apacheiravata\":{\"repo_url\":\"https://github.com/apache/airavata\"},\n",
    "            \"joblib\":{\"repo_url\":\"https://github.com/joblib/joblib\"},\n",
    "            \"kepler\":{\"status\":\"retired\"},\n",
    "            \"kibaetl\":{\"repo_url\":\"https://github.com/thbar/kiba\", \"tool_type\":\"commercial_w_oss\"},\n",
    "            \"knimeanalyticsplatform\":{\"atlernative_tool_name\":\"knime\",\"repo_url\":\"https://github.com/knime/knime-core\"},\n",
    "            \"linkedpipesetl\":{\"repo_url\":\"https://github.com/linkedpipes/etl\"},\n",
    "            \"livy\":{\"repo_url\":\"https://github.com/apache/incubator-livy\"},\n",
    "            \"longbow\":{\"repo_url\":\"https://github.com/hecbiosim/longbow\"},\n",
    "            \"mahout\":{\"repo_url\":\"https://github.com/apache/mahout\"},\n",
    "            \"make\":{},\n",
    "            \"makeflow\":{\"repo_url\":\"https://github.com/cooperative-computing-lab/cctools\"},\n",
    "            \"nextflowworkbench\":{\"status\":\"url_not_found\"},\n",
    "            \"pentahokettle\":{\"repo_url\":\"https://github.com/pentaho/pentaho-kettle\"},\n",
    "            \"prefectcore\":{\"repo_url\":\"https://github.com/PrefectHQ/prefect\"},\n",
    "            \"presto\":{\"repo_url\":\"https://github.com/prestodb/presto\"},\n",
    "            \"qdo\":{\"repo_url\":\"https://bitbucket.org/berkeleylab/qdo\"},\n",
    "            \"rmake\":{},\n",
    "            \"ruffus\":{\"alternative_tool_names\":\"cgat-ruffus\",\"repo_url\":\"https://github.com/cgat-developers/ruffus\"},\n",
    "            \"sake\":{\"repo_url\":\"https://github.com/tonyfischetti/sake\"},\n",
    "            \"apachesamza\":{\"repo_url\":\"https://github.com/apache/samza\"},\n",
    "            \"spark\":{\"repo_url\":\"https://github.com/apache/spark\"},\n",
    "            \"sparkgraphx\":{\"repo_url\":\"https://github.com/apache/spark\"},\n",
    "            \"sparkmllib\":{\"repo_url\":\"https://github.com/apache/spark\"},\n",
    "            \"sparkpackages\":{},\n",
    "            \"sparkrddapiexamples\":{},\n",
    "            \"sparkstreaming\":{\"repo_url\":\"https://github.com/apache/spark\"},\n",
    "            \"springclouddataflow\":{\"repo_url\":\"https://github.com/spring-cloud/spring-cloud-dataflow\"},\n",
    "            \"apachestorm\":{\"repo_url\":\"https://github.com/apache/storm\"},\n",
    "            \"stpipe\":{\"status\":\"not_found\"},\n",
    "            \"streampipes\":{\"repo_url\":\"https://github.com/apache/streampipes\"},\n",
    "            \"swift\":{\"repo_url\":\"https://github.com/swift-lang/swift-k\"},\n",
    "            \"taverna\":{\"status\":\"retired\"},\n",
    "            \"tez\":{\"repo_url\":\"https://github.com/apache/tez\"},\n",
    "            \"voltdb\":{\"repo_url\":\"https://github.com/VoltDB/voltdb\"},\n",
    "            \"wallaroo\":{\"status\":\"not_found\"},\n",
    "            \"worldmake\":{\"status\":\"not_found\"},\n",
    "            \"yap\":{\"status\":\"not_found\"},\n",
    "            \"zenaton\":{\"tool_type\":\"commercial\"},\n",
    "            \"zenml\":{\"repo_url\":\"https://github.com/zenml-io/zenml\"}\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only extract the repo_url mapping from the mapping information\n",
    "flat_mapping =  {name:info[\"repo_url\"] for name,info in mapping.items() if info.get(\"repo_url\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add missing repo_url entry to tools\n",
    "df[\"repo_url\"] = df.apply(lambda x: flat_mapping.get(x[\"id\"],x[\"repo_url\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove tools with missing repo_url entry  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rows where repo_url is nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[df[\"repo_url\"].notna()]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only keep rows/tools with a GitHub code repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df[\"repo_url\"].str.contains(\"github.com\")]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset=\"repo_url\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['id', 'name', 'homepage_url', 'repo_url', 'category', 'subcategory',\n",
    "       'tool_subcategory', 'source']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save consolidated  `tools` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/04_consolidated/tools.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>homepage_url</th>\n",
       "      <th>repo_url</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>tool_subcategory</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>awesome_data_engineering</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awesome_pipelines</th>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>16</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>existing_workflow_systems</th>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>166</td>\n",
       "      <td>238</td>\n",
       "      <td>227</td>\n",
       "      <td>224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lfai_landscape</th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id  name  homepage_url  repo_url  category  \\\n",
       "source                                                                   \n",
       "awesome_data_engineering    26    26            18        26        26   \n",
       "awesome_pipelines           59    59            16        59        59   \n",
       "existing_workflow_systems  238   238           166       238       227   \n",
       "lfai_landscape              41    41            41        41        41   \n",
       "\n",
       "                           subcategory  tool_subcategory  \n",
       "source                                                    \n",
       "awesome_data_engineering            12                 2  \n",
       "awesome_pipelines                    0                 0  \n",
       "existing_workflow_systems          224                 0  \n",
       "lfai_landscape                      41                 0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(by=\"source\").count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "github",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
